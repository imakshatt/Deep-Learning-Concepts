{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMMlgHtPegp74SGrP4qF5W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imakshatt/Deep-Learning-Concepts/blob/main/Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrzykegikItd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet5(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet5, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,15)\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(\n",
        "        F.relu(self.conv1(x)), (2,2)\n",
        "    )\n",
        "    x = F.max_pool2d(\n",
        "        F.relu(self.conv2(x)), 2\n",
        "    )\n",
        "    x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "fp32_model = LeNet5()\n",
        "fp32_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cr6zjYAl5yo",
        "outputId": "cc1d828b-91b8-4a6a-a7f3-47f187a7cb94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(15, 15), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, all computation and memory are implemented as float32"
      ],
      "metadata": {
        "id": "dXlD2IwTsith"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for n,p in fp32_model.named_parameters():\n",
        "  print(n, \": \", p.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGrHJFupsuAs",
        "outputId": "eac10a4c-e5ea-4f2a-a275-9a55a623f73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight :  torch.float32\n",
            "conv1.bias :  torch.float32\n",
            "conv2.weight :  torch.float32\n",
            "conv2.bias :  torch.float32\n",
            "fc1.weight :  torch.float32\n",
            "fc1.bias :  torch.float32\n",
            "fc2.weight :  torch.float32\n",
            "fc2.bias :  torch.float32\n",
            "fc3.weight :  torch.float32\n",
            "fc3.bias :  torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Reduce the model which is fp32_model into half precision meaans convert FP32 to FP16"
      ],
      "metadata": {
        "id": "J8-qcu4vtDVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fp16_model = fp32_model.half()\n",
        "\n",
        "for n,p in fp16_model.named_parameters():\n",
        "  print(n, \": \", p.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heJetizztNIo",
        "outputId": "9c969da7-fc63-41aa-ae0d-c805aae7a99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight :  torch.float16\n",
            "conv1.bias :  torch.float16\n",
            "conv2.weight :  torch.float16\n",
            "conv2.bias :  torch.float16\n",
            "fc1.weight :  torch.float16\n",
            "fc1.bias :  torch.float16\n",
            "fc2.weight :  torch.float16\n",
            "fc2.bias :  torch.float16\n",
            "fc3.weight :  torch.float16\n",
            "fc3.bias :  torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Let's explore three modes of Quantization\n",
        "\n",
        "1.   Post-training Dynamic Quantization\n",
        "2.   Post-training Static Quantization\n",
        "3.   Quantization Aware Training\n",
        "\n"
      ],
      "metadata": {
        "id": "Jdaz1bZrt1rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-training Dynamic Quantization\n",
        "\n",
        "\n",
        "*   weights are Quantized (means FP32 to int8)\n",
        "*   Activations are Stored and read in FP32, Quantized temporarily during\n",
        "    calculation\n",
        "\n"
      ],
      "metadata": {
        "id": "m0tEZLTcu2GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.quantization\n",
        "\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    fp32_model,\n",
        "    {torch.nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "id": "nuiGNE1-uSxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGhOVPogxIVM",
        "outputId": "e4132c5f-89c5-434d-d67c-2471c863f97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(15, 15), stride=(1, 1))\n",
              "  (fc1): DynamicQuantizedLinear(in_features=400, out_features=120, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
              "  (fc2): DynamicQuantizedLinear(in_features=120, out_features=84, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
              "  (fc3): DynamicQuantizedLinear(in_features=84, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Model Size between Fp32 and int8"
      ],
      "metadata": {
        "id": "bmJKkpg3xeaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_size_of_model(model, label=\"\"):\n",
        "  torch.save(model.state_dict(), \"temp.p\")\n",
        "  size = os.path.getsize(\"temp.p\")\n",
        "  print(\"Model: \", label, ' \\t', 'Size (KB):', size/1e3)\n",
        "  os.remove('temp.p')\n",
        "  return size\n",
        "\n",
        "fp32_model_size = print_size_of_model(fp32_model, \"fp32\")\n",
        "quantized_model_size = print_size_of_model(quantized_model, \"int8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3Ohe4N7xncO",
        "outputId": "ed6411a0-00c5-44ec-af82-c2d6a3b5946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:  fp32  \t Size (KB): 165.71\n",
            "Model:  int8  \t Size (KB): 108.778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-training Static Quantization\n",
        "\n",
        "\n",
        "*   weights are Quantized (means FP32 to int8)\n",
        "*   Activations are also Quantized\n",
        "*   Calbibration required here means we have to adjust the scaling factors\n",
        "\n"
      ],
      "metadata": {
        "id": "jLN5hQq2-Yfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Static_Quant_Model = LeNet5()\n",
        "\n",
        "Static_Quant_Model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "\n",
        "torch.quantization.prepare(\n",
        "    Static_Quant_Model, inplace=True\n",
        ")\n",
        "torch.quantization.convert(\n",
        "    Static_Quant_Model, inplace=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJtJMAf7-PMD",
        "outputId": "34147d56-6ff3-46fd-917b-02d456f4b7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): QuantizedConv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "  (conv2): QuantizedConv2d(6, 16, kernel_size=(15, 15), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "  (fc1): QuantizedLinear(in_features=400, out_features=120, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp32_model_size = print_size_of_model(fp32_model, \"fp32\")\n",
        "quantized_model_size = print_size_of_model(quantized_model, \"int8\")\n",
        "Static_Quantized_model_size = print_size_of_model(Static_Quant_Model, \"Static\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP3zxc4RAMqe",
        "outputId": "3dbc0064-b8fe-417c-9d6b-bfcfcbef8dc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:  fp32  \t Size (KB): 165.71\n",
            "Model:  int8  \t Size (KB): 108.778\n",
            "Model:  Static  \t Size (KB): 93.846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take any inbuilt model\n"
      ],
      "metadata": {
        "id": "loL9nv5gAksU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision"
      ],
      "metadata": {
        "id": "RsEqOYRdAokh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model = torchvision.models.quantization.mobilenet_v2(pretrained=True, quantize=True)\n",
        "model_no_quant = torchvision.models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "\n",
        "def model_size(modl):\n",
        "  torch.save(modl.state_dict(), \"demo.pt\")\n",
        "  print(\"%.2f MB\" %(os.path.getsize(\"demo.pt\")/1e6))\n",
        "\n",
        "\n",
        "model_size(quant_model)\n",
        "model_size(model_no_quant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlEg1rixAuSd",
        "outputId": "434982a3-4b4f-4098-bfb0-a514bea7494c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/quantized/mobilenet_v2_qnnpack_37f702c5.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2_qnnpack_37f702c5.pth\n",
            "100%|██████████| 3.42M/3.42M [00:00<00:00, 14.4MB/s]\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 91.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.62 MB\n",
            "14.24 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization Aware Trainng"
      ],
      "metadata": {
        "id": "Snq00DoqzFCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qat_model = LeNet5()\n",
        "\n",
        "qat_model.qconfig = torch.ao.quantization.get_default_qat_qconfig('x86')\n",
        "\n",
        "torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "\n",
        "torch.quantization.convert(qat_model, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHH7u4LizECP",
        "outputId": "30e83191-ef09-4b0e-db1f-d0d66f479b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): QuantizedConv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "  (conv2): QuantizedConv2d(6, 16, kernel_size=(15, 15), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "  (fc1): QuantizedLinear(in_features=400, out_features=120, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_channel_affine)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp32_model_size = print_size_of_model(fp32_model, \"fp32\")\n",
        "quantized_model_size = print_size_of_model(quantized_model, \"int8\")\n",
        "Static_Quantized_model_size = print_size_of_model(Static_Quant_Model, \"Static\")\n",
        "qat_model_size = print_size_of_model(qat_model, \"QAT\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0lINGbUzfQF",
        "outputId": "66d7e2e4-6d18-4555-ed83-2e9e8a094b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:  fp32  \t Size (KB): 165.71\n",
            "Model:  int8  \t Size (KB): 108.778\n",
            "Model:  Static  \t Size (KB): 93.846\n",
            "Model:  QAT  \t Size (KB): 93.782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.randn(1,5)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaLRJUJ51Lzu",
        "outputId": "2b37455e-7543-4b74-f60b-b2b70fe47cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7223, -0.1920,  0.5035,  0.5588,  1.1065]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qt = torch.quantize_per_tensor(t, scale=0.01, zero_point=0, dtype=torch.quint8)\n",
        "qt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRLW5-oE6W9G",
        "outputId": "27903552-c6e8-41a2-bf92-89f8f778b8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.5000, 0.5600, 1.1100]], size=(1, 5),\n",
              "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
              "       scale=0.01, zero_point=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_tensor = torch.randn(2,2,3)\n",
        "float_tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Jq57N-62fS",
        "outputId": "1668a9e8-dc22-4bd5-f1c9-0887c8771361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1204,  1.7465,  0.4542],\n",
              "         [-2.3271,  0.4492, -0.9955]],\n",
              "\n",
              "        [[ 0.5896, -0.0059,  0.7946],\n",
              "         [-1.0846, -0.7051, -0.4628]]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scales = torch.tensor([0.1,0.2,0.3])\n",
        "dtype = torch.quint8\n",
        "zero_points = torch.tensor([1,0,1])\n",
        "channel_axis = 2"
      ],
      "metadata": {
        "id": "Y6nkxINv7Qfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_per_chanel = torch.quantize_per_channel(float_tensor, scales, zero_points, dtype=dtype, axis=channel_axis)\n",
        "q_per_chanel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9txHdu08C4y",
        "outputId": "ec496bae-0279-4d72-ea0c-e8408a44818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1000,  1.8000,  0.6000],\n",
              "         [-0.1000,  0.4000, -0.3000]],\n",
              "\n",
              "        [[ 0.6000,  0.0000,  0.9000],\n",
              "         [-0.1000,  0.0000, -0.3000]]], size=(2, 2, 3), dtype=torch.quint8,\n",
              "       quantization_scheme=torch.per_channel_affine,\n",
              "       scale=tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64),\n",
              "       zero_point=tensor([1, 0, 1]), axis=2)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}